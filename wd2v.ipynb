{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'or': 13, 'ra': 17, 'an': 4, 'ng': 12, 'ge': 8, 'e ': 7, ' b': 1, 'ba': 6, 'na': 11, 'a ': 3, ' a': 0, 'ap': 5, 'pp': 16, 'pl': 15, 'le': 10, ' g': 2, 'gr': 9, 'pe': 14}\n  (0, 13)\t1\n  (0, 17)\t2\n  (0, 4)\t3\n  (0, 12)\t1\n  (0, 8)\t1\n  (0, 7)\t2\n  (0, 1)\t1\n  (0, 6)\t1\n  (0, 11)\t2\n  (0, 3)\t1\n  (0, 0)\t1\n  (0, 5)\t2\n  (0, 16)\t1\n  (0, 15)\t1\n  (0, 10)\t1\n  (0, 2)\t1\n  (0, 9)\t1\n  (0, 14)\t1\n  (1, 4)\t2\n  (1, 7)\t1\n  (1, 6)\t1\n  (1, 11)\t2\n  (1, 3)\t1\n  (1, 0)\t2\n  (1, 5)\t2\n  (1, 16)\t2\n  (1, 15)\t2\n  (1, 10)\t2\n  (2, 17)\t1\n  (2, 5)\t1\n  (2, 9)\t1\n  (2, 14)\t1\n  (3, 13)\t1\n  (3, 17)\t1\n  (3, 4)\t1\n  (3, 12)\t1\n  (3, 8)\t1\n  (3, 7)\t1\n  (3, 0)\t1\n  (3, 5)\t1\n  (3, 16)\t1\n  (3, 15)\t1\n  (3, 10)\t1\n[[1 1 1 1 3 2 1 2 1 1 1 2 1 1 1 1 1 2]\n [2 0 0 1 2 2 1 1 0 0 2 2 0 0 0 2 2 0]\n [0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1]\n [1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "texts=[\"orange banana apple grape\",\"banana apple apple\",\"grape\", 'orange apple']\n",
    "# cv = CountVectorizer()\n",
    "cv = CountVectorizer(ngram_range=(2, 2)) # n-gram\n",
    "\n",
    "cv_fit=cv.fit_transform(texts) #分词后的文本预料, return document-term matrix\n",
    "print(cv.vocabulary_) # 返回所有特征词的字典，按照字母顺序分别编码\n",
    "print(cv_fit) #返回结果如(0,3) 1,表示：第0个文档中、第3个特征词的词频为1 \n",
    "print(cv_fit.toarray()) #返回文档-特征词的词频矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer()函数只考虑每个单词出现的频率；然后构成一个特征矩阵，每一行表示一个训练文本的词频统计结果。\n",
    "\n",
    "其思想是，先根据所有训练文本，不考虑其出现顺序，只将训练文本中每个出现过的词汇单独视为一列特征，构成一个词汇表(vocabulary list)，该方法又称为词袋法(Bag of Words)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer()函数只考虑每个单词出现的频率；然后构成一个特征矩阵，每一行表示一个训练文本的词频统计结果。其思想是，先根据所有训练文本，不考虑其出现顺序，只将训练文本中每个出现过的词汇单独视为一列特征，构成一个词汇表(vocabulary list)，该方法又称为词袋法(Bag of Words)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'orange': 3, 'banana': 1, 'apple': 0, 'grape': 2}\n  (0, 2)\t0.5230350301866413\n  (0, 0)\t0.423441934145613\n  (0, 1)\t0.5230350301866413\n  (0, 3)\t0.5230350301866413\n  (1, 0)\t0.8508160982744233\n  (1, 1)\t0.5254635733493682\n  (2, 2)\t1.0\n  (3, 0)\t0.6292275146695526\n  (3, 3)\t0.7772211620785797\n[[0.42344193 0.52303503 0.52303503 0.52303503]\n [0.8508161  0.52546357 0.         0.        ]\n [0.         0.         1.         0.        ]\n [0.62922751 0.         0.         0.77722116]]\n"
     ]
    }
   ],
   "source": [
    "cv = TfidfVectorizer()\n",
    "cv_fit=cv.fit_transform(texts)\n",
    "print(cv.vocabulary_)\n",
    "print(cv_fit)\n",
    "print(cv_fit.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置词向量的维度\n",
    "num_features = 300\n",
    "# 保证被考虑的词汇的频度\n",
    "min_word_count = 20\n",
    "# 并行计算使用cpu核心数量\n",
    "num_workers = 2\n",
    "# 定义训练词向量的上下文窗口大小\n",
    "context = 5\n",
    "downsapling = 1e-3\n",
    "\n",
    "# 训练词向量模型\n",
    "model = word2vec.Word2Vec(sentences,\n",
    "                          workers=num_workers,\n",
    "                          size=num_features,\n",
    "                          min_count=min_word_count,\n",
    "                          window=context,\n",
    "                          sample=downsapling)\n",
    "# 这个设定代表当前训练好的词向量为最终版, 也可以加速模型训练的速度\n",
    "model.init_sims(replace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
